# PyG的图数据
## Data
一个单独的图在PyG中表示为`torch_geometric.Data`,`Data`类有以下属性:

- `data.x`: 节点特征矩阵——`[num_nodes, num_node_features]`
- `data.edge_index`:COO格式的图连通关系`[2, num_edges]`类型是`torch.long`
- `data.edge_attr`: 边特征矩阵——`[num_edges, num_edge_features]`
- `data.y`: 训练标签, 节点级标签——`[num_nodes, *]` or 图级别标签——`[1, *]`
- `data.pos`: 节点位置矩阵(理解成地理位置坐标)`[num_nodes, num_dimensions]`

这些attr都不是必需的。Data对象不局限于这些属性。例如，扩展data.face保存3D网格中的连通性，该张量的形状为`[3,num_faces]`，类型为`torch.long`。

`<simple example>`

```python
import torch
from torch_geometric.data import Data
# 注意这里的无向边是用双向边表示的
edge_index = torch.tensor([[0, 1, 1, 2],
                           [1, 0, 2, 1]], dtype=torch.long)
x = torch.tensor([[-1], [0], [1]], dtype=torch.float)

data = Data(x=x, edge_index=edge_index)
print(data)
# Data(x=[3, 1], edge_index=[2, 4])
```
<center><img src=" .\pics\1.1.example_1.png " width="500" height = "250" ></center>

### Data的方法

```python
print(data.keys)
print("-" * 50)
print(data['x'])
print("-" * 50)
for key, item in data:
    print(f'{key} found in data')
print("-" * 50)
print('edge_attr' in data)
print("-" * 50)
print(data.num_nodes)
print("-" * 50)
print(data.num_edges)
print("-" * 50)
print(data.num_node_features)
print("-" * 50)
print(data.has_isolated_nodes())
print("-" * 50)
print(data.has_self_loops())
print("-" * 50)
print(data.is_directed())
print("-" * 50)

# Transfer data object to GPU.
device = torch.device('cuda')
data = data.to(device)
```

## 通用基准数据集
PyG 包含大量通用基准数据集，例如，所有 Planetoid 数据集（Cora、Citeseer、Pubmed）、来自[http://graphkernels.cs.tu-dortmund.de](http://graphkernels.cs.tu-dortmund.de)的所有图形分类数据集及其cleaned版本、QM7 和 QM9数据集，以及少数 3D 网格/点云数据集，如 FAUST、ModelNet10/40 和 ShapeNet。

初始化数据集很简单。数据集的初始化将自动下载其原始文件并将其处理为先前描述的Data格式。 例如，要加载 ENZYMES 数据集(由 6 个类中的 600 个图组成):
```python
from torch_geometric.datasets import TUDataset

dataset = TUDataset(root='../datas/ENZYMES', name='ENZYMES')
print("length of ENZYMES:{}".format(len(dataset)))
print("num classes:{}".format(dataset.num_classes))
print("num node features:{}".format(dataset.num_node_features))
```

## mini-batch
PyG 通过创建稀疏块对角邻接矩阵(由edge_index定义)并在**节点维度连接特征和目标矩阵**来实现mini-batch的并行化。这种组合允许在一批示例中使用不同数量的节点和边。

- 实际上是先将矩阵分块，然后根据分块**重排节点**(包括特征及其对应的label)

$$
\begin{split}\mathbf{A} = \begin{bmatrix} \mathbf{A}_1 & & \\ & \ddots & \\ & & \mathbf{A}_n \end{bmatrix}, \qquad \mathbf{X} = \begin{bmatrix} \mathbf{X}_1 \\ \vdots \\ \mathbf{X}_n \end{bmatrix}, \qquad \mathbf{Y} = \begin{bmatrix} \mathbf{Y}_1 \\ \vdots \\ \mathbf{Y}_n \end{bmatrix}\end{split}
$$

PyG的`torch_geometric.loader.DataLoader`，自动处理该连接过程。

### 关于mini-batch的进一步解释

  首先解释PyG中的Data类:
1. Data类的x是`shape: [num_node, num_node_features]`
2. Data类的edge_index是`shape: [2, num_edges]`,其中2这个维度是起始出节点索引和入节点索引,而该索引是与x中的`num_node`一一对应的。
   
对于多图数据(每个样本一个图,比如`ENZYMES`), 实际上mini-batch在PyG中的实现是将采样到的样本的节点全部concat在一起,然后reindex,其中包括edge_index的重索引以及节点的重索引。

举例来说,假设`batch_size = 3`, 假设采样到第`[1,2,3]`的样本,那么第二个采样到的样本的`node_index`就是在第一个样本后继续排。

其中有:
```python
import torch
x1 = torch.tensor([[1],[1.1],[0.1]], dtype = torch.float)
x2 = torch.tensor([[2],[2.2],[0.2]], dtype = torch.float)
x3 = torch.tensor([[3],[3.3],[0.3]], dtype = torch.float)

# 公有的edge_index
global_edge_index = torch.tensor([[0, 1, 1, 2],
                                  [1, 0, 2, 1]], dtype=torch.long)
```
那么最后得到的batch如下:
```python
print(batch.x)
# tensor([[1.0],[1.1],[0.1],
#         [2.0],[2.2],[0.2],
#         [3.0],[3.3],[0.3]])

print(batch.edge_index)
# tensor([0, 1, 1, 2, 3, 4, 4, 5, 6, 7, 7, 8],
#        [1, 0, 2, 1, 4, 3, 5, 4, 7, 6, 8, 7])


print(batch.batch) 
# tensor([0, 0, 0, 1, 1, 1, 2, 2, 2])

# 对应batch.x的切分段: len(batch.batch) + 1
print(batch.ptr) 
# tensor([0,3,6,9])
```