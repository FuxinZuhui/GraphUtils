# Notes for Pytorch

## `Tensor.contiguous()`

torch中一些操作会改变原数据——`narrow()`,`view()`,`expand()`,`transpose()`等操作。这些操作pytorch并不会创建新的tensor，而是修改了tensor原地址中的一些元数据。转置的tensor和原tensor的**内存是共享的**——`contiguous`方法就类似深拷贝，使得上面这些操作不会改变元数据

## `torch.randperm(n)`

torch.randperm(random permutation): 将`[0, n-1]`随机打乱后获得的数字序列。

## `torch.matmul`

### `matmul`
- 1D and 1D   
点积
```python
seq_1 = torch.tensor([1,2,3])
seq_2 = torch.tensor([2,3,4])
print(torch.matmul(seq_1, seq_2).item())
# 20
```
- 2D and 2D     
```python
mat_1 = torch.tensor([[1,2,3],[3,4,5]])
mat_2 = torch.tensor([[2,2],[1,3],[4,5]])
print(torch.matmul(mat_1, mat_2).numpy())
# [[16 23]
#  [30 43]]
```
- 1D and 2D     
这种情况下, 一维张量只能在shape最左的位置增加维度,即`(3)->(1,3)`
```python
print(torch.matmul(seq_1, mat_2).numpy())
# [16 23]
```
- 2D and 1D     
这种情况下, 一维张量只能在shape最右的位置开始增加维度,即`(3)->(3,1)`
```python
print(torch.matmul(mat_1, seq_1).numpy())
# [14 26]
```
### others

- `mul`:点乘, shape要求一样, 可以应用于矩阵
- `dot`:点乘, 只能应用于一维张量
- `mm`:矩阵相乘